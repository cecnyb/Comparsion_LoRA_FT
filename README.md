# Comparsion_LoRA_FT
A comparison of using LoRA for Fine-Tuning an LLM versus freezing top layers
